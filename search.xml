<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>python scrapy -o 方式按指定顺序导出csv</title>
    <url>/2020/07/21/scrapy-data-save/</url>
    <content><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>最近在学习python爬虫的scrapy框架，本文记录下遇到的问题和解决方案。</p>
<hr>
<p>如果你不知道什么是scrapy，请移步：</p>
<p><a href="https://www.osgeo.cn/scrapy/intro/tutorial.html" target="_blank" rel="noopener">Scrapy 教程</a></p>
<p><a href="https://scrapy-chs.readthedocs.io/zh_CN/0.24/index.html" target="_blank" rel="noopener">Scrapy 0.24 文档</a></p>
<h2 id="正文"><a href="#正文" class="headerlink" title="正文"></a>正文</h2><p>由于需要爬取大量的地址交易信息数据，如何保存这些数据是个很大的问题。</p>
<p>最开始我是这样的：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">with</span> open(<span class="string">'xxx.txt'</span>,<span class="string">'a'</span>,encoding=<span class="string">'utf-8'</span>) <span class="keyword">as</span> fw:</span><br><span class="line">	fw.write(<span class="string">'&#123;&#125;\t&#123;&#125;'</span>.format(xxx,xxxx))</span><br></pre></td></tr></table></figure>

<p>把全部数据都写入一个txt文件中，然后再复制到表格中去，现在想起来，好蠢！</p>
<p><img src="/2020/07/21/scrapy-data-save/image-20200721152719497.png" alt="image-20200721152719497"></p>
<hr>
<p>后来我又学会了使用xlwt库，于是又变成了这样：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> xlwt</span><br><span class="line"></span><br><span class="line">workbook = xlwt.Workbook(encoding=<span class="string">'utf-8'</span>)</span><br><span class="line">worksheet = workbook.add_sheet(<span class="string">'My Worksheet'</span>)</span><br><span class="line">font = xlwt.Font()</span><br><span class="line">font.name = <span class="string">'宋体'</span></span><br><span class="line">font.height = <span class="number">20</span> * <span class="number">11</span></span><br><span class="line">style = xlwt.XFStyle()</span><br><span class="line">style.font = font</span><br><span class="line">isFinish = <span class="literal">True</span></span><br><span class="line">title = [<span class="string">'xx'</span>, <span class="string">'xxxx'</span>, <span class="string">'xxxxx'</span>, <span class="string">'xxxxx'</span>, <span class="string">'xxxxxx'</span>]</span><br><span class="line"><span class="keyword">for</span> x <span class="keyword">in</span> range(<span class="number">0</span>, len(title)):</span><br><span class="line">	worksheet.write(<span class="number">0</span>, x, title[x], style)</span><br><span class="line">workbook.save(<span class="string">'&#123;&#125;xxxx.xls'</span>)</span><br></pre></td></tr></table></figure>

<p>于是乎，是这样的：</p>
<p><img src="/2020/07/21/scrapy-data-save/image-20200721153318149.png" alt="image-20200721153318149"></p>
<hr>
<p>用了一段时间xlwt后，遇到了一次超过65536行数据的情况，由于xlwt只能操作xls表格文件，xlwt就显得不够用了，一通搜索后，我换了openpyxl：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> openpyxl <span class="keyword">import</span> Workbook</span><br><span class="line"></span><br><span class="line">workbook = Workbook()</span><br><span class="line">ws = workbook.active</span><br><span class="line">worksheet = workbook.create_sheet(<span class="string">'xxx'</span>)</span><br><span class="line">title = [<span class="string">'id'</span>, <span class="string">'tx_hash'</span>, <span class="string">'created_ts'</span>, <span class="string">'sender_hash'</span>, <span class="string">'receiver_hash'</span>, <span class="string">'amount'</span>, <span class="string">'status'</span>, <span class="string">'tx_type'</span>]</span><br><span class="line">ws.append(title)</span><br><span class="line">workbook.save(<span class="string">'&#123;&#125;xxxx.xlsx'</span>)</span><br></pre></td></tr></table></figure>

<p>这下好了，xlsx最大能够存储1048576行数据，能够完全满足使用了，再大的数据量就得使用数据库了。</p>
<hr>
<p>本来到这里也应该结束，本文也不该出现的。有天突（xian）发（de）奇（dan）想（teng），想着减少一下爬虫得代码量，正好scrapy本身也提供了item来接受数据，于是我改了下我的代码，把openpyxl代码全部删掉。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#items.py</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">GetallEthtxsItem</span><span class="params">(scrapy.Item)</span>:</span></span><br><span class="line">    <span class="comment"># define the fields for your item here like:</span></span><br><span class="line">    id = scrapy.Field()</span><br><span class="line">    created_ts = scrapy.Field()</span><br><span class="line">    tx_hash = scrapy.Field()</span><br><span class="line">    amount = scrapy.Field()</span><br><span class="line">    sender_hash = scrapy.Field()</span><br><span class="line">    receiver_hash = scrapy.Field()</span><br><span class="line">    status = scrapy.Field()</span><br><span class="line">    tx_type = scrapy.Field()</span><br><span class="line">    </span><br><span class="line"><span class="comment">#myspider.py</span></span><br><span class="line">item = GetallEthtxsItem()</span><br><span class="line">timeArray = time.localtime(result[x][<span class="string">'created_ts'</span>])</span><br><span class="line">item[<span class="string">'id'</span>] = result[x][<span class="string">'id'</span>]</span><br><span class="line">item[<span class="string">'created_ts'</span>] = time.strftime(<span class="string">"%Y-%m-%d %H:%M:%S"</span>, timeArray)</span><br><span class="line">item[<span class="string">'tx_hash'</span>] = result[x][<span class="string">'tx_hash'</span>]</span><br><span class="line">item[<span class="string">'amount'</span>] = result[x][<span class="string">'amount'</span>]</span><br><span class="line">item[<span class="string">'sender_hash'</span>] = result[x][<span class="string">'sender_hash'</span>]</span><br><span class="line">item[<span class="string">'receiver_hash'</span>] = result[x][<span class="string">'receiver_hash'</span>]</span><br><span class="line">item[<span class="string">'status'</span>] = result[x][<span class="string">'status'</span>]</span><br><span class="line">item[<span class="string">'tx_type'</span>] = result[x][<span class="string">'tx_type'</span>]</span><br><span class="line"><span class="keyword">yield</span> item</span><br><span class="line"></span><br><span class="line"><span class="comment">#启动爬虫，并导出xxxx.csv格式数据</span></span><br><span class="line">scrapy crawl spiderName -o xxxx.csv</span><br></pre></td></tr></table></figure>

<p>换了这种方式后，代码看着一下就舒服多了（至于效率有没有提高，就不知道了，hahahaha~~）。</p>
<p>于是本篇文章正文来了：</p>
<p><img src="/2020/07/21/scrapy-data-save/image-20200721154814042.png" alt="image-20200721154814042"></p>
<p>如上图所示，导出的csv文件内部title并不是我所期望的结果!</p>
<p>于是在Google上搜了搜：</p>
<p><img src="/2020/07/21/scrapy-data-save/image-20200721155041990.png" alt="image-20200721155041990"></p>
<p>这些文章里面大多都是使用的如下方式：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#在scrapy的spiders同层目录，新建my_project_csv_item_exporter.py文件内容如下（文件名可改，目录定死）</span></span><br><span class="line"><span class="keyword">from</span> scrapy.conf <span class="keyword">import</span> settings</span><br><span class="line"><span class="keyword">from</span> scrapy.contrib.exporter <span class="keyword">import</span> CsvItemExporter</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MyProjectCsvItemExporter</span><span class="params">(CsvItemExporter)</span>:</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, *args, **kwargs)</span>:</span></span><br><span class="line">        delimiter = settings.get(<span class="string">'CSV_DELIMITER'</span>, <span class="string">','</span>)</span><br><span class="line">        kwargs[<span class="string">'delimiter'</span>] = delimiter</span><br><span class="line"></span><br><span class="line">        fields_to_export = settings.get(<span class="string">'FIELDS_TO_EXPORT'</span>, [])</span><br><span class="line">        <span class="keyword">if</span> fields_to_export :</span><br><span class="line">            kwargs[<span class="string">'fields_to_export'</span>] = fields_to_export</span><br><span class="line"></span><br><span class="line">        super(MyProjectCsvItemExporter, self).__init__(*args, **kwargs)</span><br><span class="line"></span><br><span class="line"><span class="comment">#settings.py中</span></span><br><span class="line">FEED_EXPORTERS = &#123;                                                        </span><br><span class="line">    <span class="string">'csv'</span>: <span class="string">'jsuser.spiders.csv_item_exporter.MyProjectCsvItemExporter'</span>,   </span><br><span class="line">&#125; <span class="comment">#jsuser为工程名                                                                                                                </span></span><br><span class="line">FIELDS_TO_EXPORT = [                                                </span><br><span class="line">    <span class="string">'author'</span>,                                                             </span><br><span class="line">    <span class="string">'title'</span>,                                                              </span><br><span class="line">    <span class="string">'url'</span>,                                                                </span><br><span class="line">    <span class="string">'reads'</span>,                                                              </span><br><span class="line">    <span class="string">'comments'</span>,                                                           </span><br><span class="line">    <span class="string">'likes'</span>,                                                              </span><br><span class="line">    <span class="string">'rewards'</span>                                                             </span><br><span class="line">]</span><br></pre></td></tr></table></figure>

<p>我照着他这个做了：</p>
<p>然鹅，引入都出现了问题，搜索之后发现 .conf以及.contrib已经在1.7.x版本中就废弃了，我用的是2.2.0版本，所以得使用其他得导入方式。</p>
<p><img src="/2020/07/21/scrapy-data-save/image-20200721155440701.png" alt="image-20200721155440701"></p>
<p>删除错误的导入后，利用pycharm的自带快速导入：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">from getAllTxs import settings</span><br><span class="line">from scrapy.exporters import CsvItemExporter</span><br></pre></td></tr></table></figure>

<p>然后又报错：</p>
<p><img src="/2020/07/21/scrapy-data-save/image-20200721160222218.png" alt="image-20200721160222218"></p>
<p>在<a href="https://www.cnblogs.com/banshaohuan/p/11848264.html" target="_blank" rel="noopener">新版 Scrapy 中 sys.conf.settings 的替代方法</a>看到了解决方法：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> scrapy.conf <span class="keyword">import</span> settings</span><br><span class="line"><span class="comment">#替换为</span></span><br><span class="line"><span class="keyword">from</span> scrapy.utils.project <span class="keyword">import</span> get_project_settings</span><br><span class="line">settings = get_project_settings()</span><br></pre></td></tr></table></figure>

<p>然后，令人吃惊的事情发生了:</p>
<p><img src="/2020/07/21/scrapy-data-save/image-20200721161128541.png" alt="image-20200721161128541"></p>
<p>成功的按照自己想要的顺序写入了cvs文件中（写这篇文章之前，试了好多次都没成功，结果写文章的时候就好了！）。</p>
<hr>
<p>因为最开始的时候，遇到了csv中顺序错误的问题，然后搜索了一堆解决方案也没有解决，我就放弃了上面的那种方式（谁知道它现在就好了！），找到了另一种更为简单的方式。</p>
<p>不得不说stack overflow真的是个好东西，以前好几次在其他地方找不到解决方法的问题，都是在上面得到了解决。</p>
<p>在<a href="https://stackoverflow.com/questions/20753358/how-can-i-use-the-fields-to-export-attribute-in-baseitemexporter-to-order-my-scr" target="_blank" rel="noopener">How can I use the fields_to_export attribute in BaseItemExporter to order my Scrapy CSV data?</a>这篇文章中使用了custom_settings的方式，在spider中进行定义，不需要额外的设置什么东西就能够让csv按照自己想要的顺序进行输出。</p>
<p><img src="/2020/07/21/scrapy-data-save/image-20200721161905518.png" alt="image-20200721161905518"></p>
<h2 id="后记"><a href="#后记" class="headerlink" title="后记"></a>后记</h2><p>至此，本文所描述的内容已经结束。通过本次问题的解决过程，发现了自己在进行实际操作的时候还是可能会遗漏些问题，以后还得更加细心啊。</p>
<p>完结<em>★,°</em>:.☆(￣▽￣)/$:<em>.°★</em> 。。</p>
]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>scrapy</tag>
        <tag>python</tag>
        <tag>爬虫</tag>
      </tags>
  </entry>
  <entry>
    <title>etherscan自定义标签插件编写</title>
    <url>/2020/07/20/etherscan-tags/</url>
    <content><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p><em>Etherscan 是</em>以太坊上应用最广泛的区块链浏览器，日常工作中经常需要使用到它。在实际使用中，经常需要在不同的地址交易信息之间来回切换，有时候会忘记了哪个地址是什么的地址。于是乎某个周五的日常工（mo）作（yu）中和同事聊到了这个，在网上搜索也没有看见有类似的插件（有也当没看见，哈哈哈哈<del>~</del>），于是突发奇想——要是做个插件，让浏览器在加载页面的时候就将自己自定义的标签渲染出来，岂不美哉！</p>
<hr>
<p>下面就是实现的效果：</p>
<p><img src="/2020/07/20/etherscan-tags/image-20200714095712858.png" alt="image-20200714095712858"></p>
<p>PS：由于本人CSS、Html等知识严重缺乏，没有对那些按钮啥的进行美化，全部都是用的默认样式，难看是难看了一点，能用就行<del>~</del></p>
<h2 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h2><p>要完成一个自定义标签插件的实现，最开始面临的问题主要是两个方面：一是插件的编写；二是自定义标签数据存储在什么地方。</p>
<h2 id="过程"><a href="#过程" class="headerlink" title="过程"></a>过程</h2><p>首先是第一个问题，插件的编写。百度、谷歌一搜，一大堆的编写教程，这个倒不是什么大问题。</p>
<p>主要参考了一下文章：</p>
<p><a href="https://www.jianshu.com/p/146ab0ca3246" target="_blank" rel="noopener">从零开始编写一个chrome插件</a></p>
<p><a href="https://juejin.im/post/5c135a275188257284143418" target="_blank" rel="noopener">一篇文章教你顺利入门和开发chrome扩展程序（插件）</a></p>
<p><a href="https://blog.csdn.net/qq_41368391/article/details/105996336" target="_blank" rel="noopener">chrome浏览器网页通过插件形式，自动调用js脚本</a></p>
<p><a href="https://www.cnblogs.com/liuxianan/p/chrome-plugin-develop.html" target="_blank" rel="noopener">【干货】Chrome插件(扩展)开发全攻略</a></p>
<p><a href="https://developer.chrome.com/extensions" target="_blank" rel="noopener">chrome官方插件开发文档</a></p>
<p>最基础的一个插件是由两个部分组成的：一个是manifest文件，它用于描述 Chrome 插件的源数据，配置信息等；二是js文件，js不用多解释吧，你要实现的功能基本都在里面写。</p>
<p>manifest.json文件基础内容如下所示：</p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line">&#123;</span><br><span class="line">   <span class="string">"name"</span>: <span class="string">"Hello Extensions"</span>,</span><br><span class="line">   <span class="string">"description"</span> : <span class="string">"Hello world Extension"</span>,</span><br><span class="line">   <span class="string">"version"</span>: <span class="string">"1.0"</span>,</span><br><span class="line">   <span class="string">"manifest_version"</span>: <span class="number">2</span>,</span><br><span class="line">   <span class="string">"icons"</span>:&#123;</span><br><span class="line">       <span class="string">"16"</span>: <span class="string">"img/icon.png"</span>,</span><br><span class="line">       <span class="string">"48"</span>: <span class="string">"img/icon.png"</span>,</span><br><span class="line">       <span class="string">"128"</span>: <span class="string">"img/icon.png"</span></span><br><span class="line"> 	&#125;,</span><br><span class="line"> <span class="string">"content_scripts"</span>: [</span><br><span class="line">   &#123;</span><br><span class="line">     <span class="string">"matches"</span>: [</span><br><span class="line">       <span class="string">"http://*/*"</span>,</span><br><span class="line">       <span class="string">"https://*/*"</span></span><br><span class="line">     ],</span><br><span class="line">     <span class="string">"js"</span>: [</span><br><span class="line">       <span class="string">"scripts/contentscript.js"</span></span><br><span class="line">     ],</span><br><span class="line">     <span class="string">"all_frames"</span>: <span class="literal">false</span></span><br><span class="line">   &#125;</span><br><span class="line"> ]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>name：必填项，插件的名字。</p>
<p>description：插件的描述，132个字符的限制。</p>
<p>version：插件的版本号，打包完成后用于判断插件是否需要更新。</p>
<p>manifest_version ：必填项，指定插件使用的清单文件规范的版本，chrome官方文档使用的是2。</p>
<p>Content Scripts：运行在Web页面的上下文的JavaScript文件。通过标准的DOM，Content Scripts 可以操作（读取并修改）浏览器当前访问的Web页面的内容。</p>
<p>icons：插件的图标，可以用在 Chrome 商店展示(128 * 128) | 插件管理界面 (48 * 48) | 扩展页图标 (16 * 16) 最好是 png 格式。</p>
<p>mathches：选择插件默认在什么网站上生效。</p>
<p>js：引入自己写js文件。</p>
<p>all_frames：控制JS文件是否在匹配的Web页面中的所有框架中运行。默认false表示只在顶层框架中运行。</p>
<hr>
<p>然后是第二个问题，自定义标签的数据存储在什么地方。</p>
<p>最开始的想的是能不能直接读取本地文件然后进行数据的更新，然鹅chrome的安全策略给了我当头一棒。</p>
<p>在js中尝试读取本地文件时，控制台中报了如下错误：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Not allowed to load local resource: file// XXXX</span><br></pre></td></tr></table></figure>

<p>然后百度、谷歌一顿搜索：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">解决方法有这样的：</span><br><span class="line">	修改快捷方式的属性中的目标为下面这样：</span><br><span class="line">	&quot;C:\Program Files (x86)\Google\Chrome\Application\chrome.exe&quot; --args --disable-web-security --allow-file-access-from-files</span><br><span class="line">	</span><br><span class="line">有这样的：</span><br><span class="line">	安装LocalLinks插件</span><br><span class="line"></span><br><span class="line">上面两种方式我都有试过，但是！不知道是不是我自己的原因，问题并没有得到解决，chrome还是一样的报错！</span><br></pre></td></tr></table></figure>

<p>于是乎继续搜索：</p>
<p><a href="https://www.itdaan.com/blog/2016/11/21/13c3c7db987b2f8d6c98d18565778ddd.html" target="_blank" rel="noopener">解決chrome報Not allowed to load local resource錯誤的方法</a>文中提到了Tomcat下可以使用目录映射的方式，可惜的是我没有用Tomcat呀!</p>
<p><a href="https://www.codenong.com/cs105905824/" target="_blank" rel="noopener">解决Chrome浏览器Not allowed to load local resource</a>这篇文章提到了使用搭建本地服务器的形式来解决这个问题，我最初的实现方式也是这样。</p>
<p>实现本地服务器的方式有很多，我以前用的主要是使用phpstudy以及nodejs。</p>
<hr>
<p>phpstudy的使用方式，百度一堆，这里就不在赘述。</p>
<p>安装完成后将数据json文件放在网站根目录后，再次尝试在网站上访问，然后chrome报了这种类型的错：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Mixed Content: The page at &apos;https://googlesamples.github.io/web-fundamentals/fundamentals/security/prevent-mixed-content/simple-example.html&apos; was loaded over HTTPS, but requested an insecure script &apos;http://googlesamples.github.io/web-fundamentals/fundamentals/security/prevent-mixed-content/simple-example.js&apos;. This request has been blocked; the content must be served over HTTPS.</span><br></pre></td></tr></table></figure>

<p>大概意思就是不能在https网站中使用http请求来访问资源。</p>
<p>又双叒叕是一通百度，最后发现在phpstudy中可以切换为https：</p>
<p><img src="/2020/07/20/etherscan-tags/image-20200714111524304.png" alt="image-20200714111524304"></p>
<p>只不过需要一个SSL证书，这个倒不是什么大问题，我的网站之前就有证书，直接拿下来用，改下host就可以了。</p>
<p><img src="/2020/07/20/etherscan-tags/image-20200714111702158.png" alt="image-20200714111702158"></p>
<p>改好之后便可以通过<a href="https://localhost来访问本地服务器中的文件了！" target="_blank" rel="noopener">https://localhost来访问本地服务器中的文件了！</a></p>
<p><img src="/2020/07/20/etherscan-tags/image-20200714135033177.png" alt="image-20200714135033177"></p>
<p>在js中使用Jquery获取数据：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">$.getJSON(&quot;https://xxxxx.cn:18081&quot;,function(result)&#123;</span><br><span class="line">	for(var key in result)&#123;</span><br><span class="line">		tag[key.toLowerCase()] = result[key]</span><br><span class="line">	&#125;</span><br><span class="line">&#125;);</span><br></pre></td></tr></table></figure>

<hr>
<p>然后是nodejs搭建本地服务器的方式，使用了express框架。</p>
<p>参考文章：</p>
<p><a href="https://juejin.im/post/5a7a88125188257a624cb117" target="_blank" rel="noopener">使用Express搭建https服务器</a></p>
<p>全部代码如下所示：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">var app = require(&apos;express&apos;)();</span><br><span class="line">var fs = require(&apos;fs&apos;);</span><br><span class="line">var http = require(&apos;http&apos;);</span><br><span class="line">var https = require(&apos;https&apos;);</span><br><span class="line">var privateKey  = fs.readFileSync(&quot;./https/https.key&quot;, &apos;utf8&apos;);</span><br><span class="line">var certificate = fs.readFileSync(&quot;./https/https.crt&quot;, &apos;utf8&apos;);</span><br><span class="line">var credentials = &#123;key: privateKey, cert: certificate&#125;;</span><br><span class="line"></span><br><span class="line">var httpServer = http.createServer(app);</span><br><span class="line">var httpsServer = https.createServer(credentials, app);</span><br><span class="line">var PORT = 18080;</span><br><span class="line">var SSLPORT = 18081;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">//设置允许跨域</span><br><span class="line">app.all(&apos;*&apos;,function(req,res,next)&#123;</span><br><span class="line">  res.header(&quot;Access-Control-Allow-Origin&quot;,&quot;*&quot;);</span><br><span class="line">  res.header(&quot;Access-Control-Allow-Methods&quot;,&quot;PUT,GET,POST,DELETE,OPTIONS&quot;);</span><br><span class="line">  res.header(&apos;Access-Control-Allow-Headers&apos;, &apos;Content-Type, Content-Length, Authorization, Accept, X-Requested-With , yourHeaderFeild&apos;);</span><br><span class="line">  next();</span><br><span class="line">&#125;);</span><br><span class="line"></span><br><span class="line">httpServer.listen(PORT, function() &#123;</span><br><span class="line">    console.log(&apos;HTTP Server is running on: http://localhost:%s&apos;, PORT);</span><br><span class="line">&#125;);</span><br><span class="line">httpsServer.listen(SSLPORT, function() &#123;</span><br><span class="line">    console.log(&apos;HTTPS Server is running on: https://localhost:%s&apos;, SSLPORT);</span><br><span class="line">&#125;);</span><br><span class="line"></span><br><span class="line">// Welcome</span><br><span class="line">app.get(&apos;/&apos;, function(req, res) &#123;</span><br><span class="line">    if(req.protocol === &apos;https&apos;) &#123;</span><br><span class="line">        var file=&quot;./addr_tag.json&quot;;</span><br><span class="line">        var result=JSON.parse(fs.readFileSync(file));</span><br><span class="line">        console.log(result)</span><br><span class="line">        res.send(result)</span><br><span class="line">    &#125;</span><br><span class="line">    else &#123;</span><br><span class="line">        res.status(200).send(&apos;Welcome!&apos;);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;);</span><br></pre></td></tr></table></figure>

<p>在采用nodejs方式搭建时，由于有了phpstudy的失败经历，nodejs直接选择了https形式的搭建，过程中没有在遇到其他的问题，成功实现了数据的获取。</p>
<p><img src="/2020/07/20/etherscan-tags/image-20200714115438099.png" alt="image-20200714115438099"></p>
<hr>
<p>做完之后，不禁想到，搭建服务器的方式有点太复杂了，https证书也麻烦，于是又想了一下。想到了直接在插件的js文件中保存数据即可，直接将数据存入addr_tag.js文件中，在manifest文件中导入后，直接在contentscript.js文件中使用即可，以后每次修改数据直接在add_tag文件中修改即可，不需要经历繁琐的步骤去搭建服务器了。</p>
<p><img src="/2020/07/20/etherscan-tags/image-20200714113039494.png" alt="image-20200714113039494"></p>
<hr>
<p>后来第二天上班的时候，把我做好的这个两个版本给同事看了之后，他问我为啥不用localstorage来存储数据？？？Excuse me？？？为啥我把这个给忘了！</p>
<p>于是我又改了改代码，直接使用localstorage.getItem来获取里面的数据，然后在加载到页面上。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">var tokenTag = document.getElementsByClassName(&apos;hash-tag text-truncate&apos;);</span><br><span class="line">for(var x =0;x&lt;tokenTag.length;x++)&#123;</span><br><span class="line">	if(localStorage.getItem((ethTag[x].innerText.toLowerCase()))!=undefined)&#123;</span><br><span class="line">	tokenTag[x].innerText =	&apos;Local:&apos;+localStorage.getItem(ethTag[x].innerText.toLowerCase());</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p><img src="/2020/07/20/etherscan-tags/image-20200714120032496.png" alt="image-20200714120032496"></p>
<p>虽然能够避免繁琐的前置步骤了，但在使用中，同</p>
<hr>
<p>事又提出了新的”需求“——每次更新数据都要打开F12，太麻烦了。</p>
<p>参考文章：</p>
<p><a href="https://www.cnblogs.com/f-l-y/p/8991247.html" target="_blank" rel="noopener">js动态往div里添加按钮的两种方式</a></p>
<p><a href="https://blog.csdn.net/wei13636075/article/details/25219039" target="_blank" rel="noopener">JS打开选择本地文件的对话框</a></p>
<p><a href="https://www.jianshu.com/p/40cfe9a12f9e" target="_blank" rel="noopener">javascript实现生成并下载txt文件</a></p>
<p>于是有了下面的代码：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">var MyDiv =document.getElementById(&quot;logoAndNav&quot;);</span><br><span class="line"></span><br><span class="line">var addr_data =document.createElement(&apos;input&apos;);</span><br><span class="line">   addr_data.setAttribute(&apos;type&apos;, &apos;text&apos;);//输入框的类型</span><br><span class="line">   addr_data.setAttribute(&quot;placeholder&quot;, &quot;地址&quot;);</span><br><span class="line">   addr_data.setAttribute(&apos;id&apos;,&apos;addr_data&apos;)</span><br><span class="line">   addr_data.style.width = &quot;16%&quot;;</span><br><span class="line">   MyDiv.appendChild(addr_data);</span><br><span class="line"></span><br><span class="line">   var tag_data =document.createElement(&apos;input&apos;);</span><br><span class="line">   tag_data.setAttribute(&apos;type&apos;, &apos;text&apos;);//输入框的类型</span><br><span class="line">   tag_data.setAttribute(&quot;placeholder&quot;, &quot;标签名&quot;);</span><br><span class="line">   tag_data.setAttribute(&apos;id&apos;,&apos;tag_data&apos;)</span><br><span class="line">   tag_data.style.width = &quot;16%&quot;;</span><br><span class="line">   MyDiv.appendChild(tag_data);</span><br><span class="line"></span><br><span class="line">  	var button = document.createElement(&quot;input&quot;);</span><br><span class="line">button.setAttribute(&quot;type&quot;, &quot;button&quot;);</span><br><span class="line">button.setAttribute(&quot;value&quot;, &quot;添加/修改标签&quot;);</span><br><span class="line">button.style.width = &quot;17%&quot;;</span><br><span class="line">button.setAttribute(&quot;onclick&quot;, </span><br><span class="line">	&quot;javascript:\</span><br><span class="line">		var addr_data = document.getElementById(&apos;addr_data&apos;); \</span><br><span class="line">		var tag_data = document.getElementById(&apos;tag_data&apos;); \</span><br><span class="line">		if(addr_data.value!=&apos;&apos;&amp;&amp;tag_data.value!=&apos;&apos;)&#123;\</span><br><span class="line">			localStorage.setItem(addr_data.value.toLowerCase(),tag_data.value);\</span><br><span class="line">			document.location.reload();\</span><br><span class="line">		&#125;\</span><br><span class="line">		else&#123;\</span><br><span class="line">			alert(\&quot;请输入数据哦！\&quot;)\</span><br><span class="line">		&#125;\</span><br><span class="line">	&quot;</span><br><span class="line">	)</span><br><span class="line">MyDiv.appendChild(button);</span><br><span class="line"></span><br><span class="line">var button2 = document.createElement(&quot;input&quot;);</span><br><span class="line">button2.setAttribute(&quot;type&quot;, &quot;button&quot;);</span><br><span class="line">button2.setAttribute(&quot;value&quot;, &quot;删除标签&quot;);</span><br><span class="line">button2.style.width = &quot;17%&quot;;</span><br><span class="line">button2.setAttribute(&quot;onclick&quot;, </span><br><span class="line">	&quot;javascript:\</span><br><span class="line">		var addr_data = document.getElementById(&apos;addr_data&apos;); \</span><br><span class="line">		if(addr_data.value!=&apos;&apos;)&#123;\</span><br><span class="line">			localStorage.removeItem(addr_data.value.toLowerCase());\</span><br><span class="line">			document.location.reload();\</span><br><span class="line">		&#125;\</span><br><span class="line">		else&#123;\</span><br><span class="line">			alert(\&quot;请输入要删除的地址哦！\&quot;)\</span><br><span class="line">		&#125;\</span><br><span class="line">	&quot;</span><br><span class="line">	)</span><br><span class="line">MyDiv.appendChild(button2);</span><br><span class="line"></span><br><span class="line">var button3 = document.createElement(&quot;input&quot;);</span><br><span class="line">button3.setAttribute(&quot;type&quot;, &quot;button&quot;);</span><br><span class="line">button3.setAttribute(&quot;value&quot;, &quot;导出标签&quot;);</span><br><span class="line">button3.style.width = &quot;17%&quot;;</span><br><span class="line">button3.setAttribute(&quot;onclick&quot;, </span><br><span class="line">	&quot;javascript:\</span><br><span class="line">		var output_data=&#123;&#125;;\</span><br><span class="line">		for(var i=0;i&lt;localStorage.length;i++)&#123;\</span><br><span class="line">			output_data[localStorage.key(i)] = localStorage.getItem(localStorage.key(i));\</span><br><span class="line">		&#125;\</span><br><span class="line">		function download(filename, text) &#123;\</span><br><span class="line">		    var pom = document.createElement(&apos;a&apos;);\</span><br><span class="line">		    pom.setAttribute(&apos;href&apos;, &apos;data:text/plain;charset=utf-8,&apos; + encodeURIComponent(text));\</span><br><span class="line">		    pom.setAttribute(&apos;download&apos;, filename);\</span><br><span class="line">		    if (document.createEvent) &#123;\</span><br><span class="line">		        var event = document.createEvent(&apos;MouseEvents&apos;);\</span><br><span class="line">		        event.initEvent(&apos;click&apos;, true, true);\</span><br><span class="line">		        pom.dispatchEvent(event)\</span><br><span class="line">		    &#125; else &#123;\</span><br><span class="line">		        pom.click();\</span><br><span class="line">		    &#125;\</span><br><span class="line">		&#125;\</span><br><span class="line">		download(&apos;tag_data.txt&apos;,JSON.stringify(output_data));\</span><br><span class="line">	&quot;</span><br><span class="line">	)</span><br><span class="line">MyDiv.appendChild(button3);</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">var inputObj=document.createElement(&apos;input&apos;)</span><br><span class="line">   inputObj.setAttribute(&apos;id&apos;,&apos;upload_data&apos;);</span><br><span class="line">   inputObj.setAttribute(&apos;type&apos;,&apos;file&apos;);</span><br><span class="line">   inputObj.setAttribute(&quot;style&quot;,&apos;visibility:hidden&apos;);</span><br><span class="line">   document.body.appendChild(inputObj);</span><br><span class="line"></span><br><span class="line">var button4 = document.createElement(&quot;input&quot;);</span><br><span class="line">button4.setAttribute(&quot;type&quot;, &quot;button&quot;);</span><br><span class="line">button4.setAttribute(&quot;value&quot;, &quot;批量导入标签&quot;);</span><br><span class="line">button4.style.width = &quot;17%&quot;;</span><br><span class="line">button4.setAttribute(&quot;onclick&quot;, </span><br><span class="line">	&quot;javascript:\</span><br><span class="line">		var input =document.getElementById(&apos;upload_data&apos;);\</span><br><span class="line">		input.click();\</span><br><span class="line">		input.addEventListener(&apos;change&apos;,()=&gt;&#123;\</span><br><span class="line">		    var reader = new FileReader();\</span><br><span class="line">		    reader.readAsText(input.files[0],&apos;utf8&apos;);\</span><br><span class="line">		    reader.onload = ()=&gt;&#123;\</span><br><span class="line">		      	var input_data = JSON.parse(reader.result);\</span><br><span class="line">				for(var key in input_data)&#123;\</span><br><span class="line">					localStorage.setItem(key,input_data[key]);\</span><br><span class="line">				&#125;\</span><br><span class="line">				document.location.reload();\</span><br><span class="line">		    &#125;\</span><br><span class="line">		&#125;, false);	\</span><br><span class="line">	&quot;)</span><br><span class="line">MyDiv.appendChild(button4);</span><br></pre></td></tr></table></figure>

<p>上面代码实现了在etherscan的页面上添加了两个输入框和四个按钮，分别是地址、标签的输入以及添加/修改标签按钮、删除标签按钮、导出标签按钮和批量导入标签按钮。</p>
<p>最终效果：</p>
<p><img src="/2020/07/20/etherscan-tags/%E6%9C%80%E7%BB%88%E6%95%88%E6%9E%9C.gif" alt="最终效果"></p>
<hr>
<p>2020.07.17更新</p>
<hr>
<p>上个版本的插件已经能够满足日常的基本使用了，但是由于localStorage的5M大小的限制，使得标签的数量被限制在了10W以下（利用假数据简单测试结果是7W多条），为了能够储存更多的数据，不得不放弃localstorage从而寻找新的思路。</p>
<p>查阅资料可以使用chrome.storage，通过在赋予unlimitedStorage权限，在本地存储区储存的数据量大小不受限制。但在实际使用过程中遇到了chrome.storage未定义的问题，有可能是我的使用方式存在问题，查询大量资料之后无果，遂放弃。</p>
<p><img src="/2020/07/20/etherscan-tags/image-20200717105731138.png" alt="image-20200717105731138"></p>
<p>在Storage中，一共有五个储存数据的地方，如上图所示，详细介绍如下表所示：</p>
<table>
<thead>
<tr>
<th align="center">sessionStorage</th>
<th align="left">sessionStorage是个全局对象，它维护着在页面会话(page session)期间有效的存储空间。只要浏览器开着，页面会话周期就会一直持续。当页面重新载入(reload)或者被恢复(restores)时，页面会话也是一直存在的。每在新标签或者新窗口中打开一个新页面，都会初始化一个新的会话。</th>
</tr>
</thead>
<tbody><tr>
<td align="center">localStorage</td>
<td align="left">localStorage与sessionStorage相同，但应用了相同的规则，但它是持久性的。LocalStorage 在 2.5MB 到 10MB 之间（各家浏览器不同），而且不提供搜索功能，不能建立自定义的索引。</td>
</tr>
<tr>
<td align="center">IndexedDB</td>
<td align="left">通俗地说，IndexedDB 就是浏览器提供的本地数据库，它可以被网页脚本创建和操作。IndexedDB 允许储存大量数据，提供查找接口，还能建立索引。这些都是 LocalStorage 所不具备的。就数据库类型而言，IndexedDB 不属于关系型数据库（不支持 SQL 查询语句），更接近 NoSQL 数据库。</td>
</tr>
<tr>
<td align="center">WebSQL</td>
<td align="left">WebSQL是一个在浏览器客户端的结构关系数据库，这是浏览器内的本地RDBMS(关系型数据库系统)</td>
</tr>
<tr>
<td align="center">cookies</td>
<td align="left">用于保存登陆信息</td>
</tr>
</tbody></table>
<p>localStorage和sessionStorage都有着大小的限制，且存储的数据类型只能是键值对形式。</p>
<p><a href="https://developer.mozilla.org/zh-CN/docs/Web/API/IndexedDB_API" target="_blank" rel="noopener">IndexedDB_API</a>中推荐8种使用IndexedDB的更方便的方式：</p>
<table>
<thead>
<tr>
<th><a href="https://localforage.github.io/localForage/" target="_blank" rel="noopener">localForage</a></th>
<th>一个简单名称的Polyfill：客户端数据存储的值语法，它在后台使用IndexedDB，但在不支持IndexedDB的浏览器中回退到WebSQL或localStorage。</th>
</tr>
</thead>
<tbody><tr>
<td><a href="http://www.dexie.org/" target="_blank" rel="noopener">Dexie.js</a></td>
<td>IndexedDB的包装器，通过简单的语法，可以更快地进行代码开发。</td>
</tr>
<tr>
<td><a href="https://github.com/erikolson186/zangodb" target="_blank" rel="noopener">ZangoDB</a></td>
<td>类似MongoDB的IndexedDB接口，支持MongoDB的大多数熟悉的过滤，投影，排序，更新和聚合功能。</td>
</tr>
<tr>
<td><a href="http://jsstore.net/" target="_blank" rel="noopener">JsStore</a></td>
<td>一个带有SQL语法的IndexedDB包装器。</td>
</tr>
<tr>
<td><a href="https://github.com/mWater/minimongo" target="_blank" rel="noopener">MiniMongo</a></td>
<td>由localstorage支持的客户端内存中的mongodb，通过http进行服务器同步。MeteorJS使用MiniMongo。</td>
</tr>
<tr>
<td><a href="https://pouchdb.com/" target="_blank" rel="noopener">PouchDB</a></td>
<td>使用IndexedDB在浏览器中实现CouchDB的客户端。</td>
</tr>
<tr>
<td><a href="https://www.npmjs.com/package/idb" target="_blank" rel="noopener">idb</a></td>
<td>一个微小的（〜1.15k）库，主要反映了IndexedDB的API，但小的改进，使一个很大的区别的可用性。</td>
</tr>
<tr>
<td><a href="https://www.npmjs.com/package/idb-keyval" target="_blank" rel="noopener">idb-keyval</a></td>
<td>使用IndexedDB实现的超简单小（~600B）基于Promise的键值存储。</td>
</tr>
</tbody></table>
<p>本次我采用的是localForage。</p>
<p>引入localforage.js文件文件后便可以利用localforage中定义的方法来进行indexedDB的使用了，而不需要去写复杂的语句。</p>
<p>插件中使用localforage很顺利，但在网页上使用出现了问题：提示localforage未定义。</p>
<p><img src="/2020/07/20/etherscan-tags/image-20200717112751028.png" alt="image-20200717112751028"></p>
<p>查阅资料后，在<a href="https://www.cnblogs.com/liuxianan/p/chrome-plugin-develop.html" target="_blank" rel="noopener">【干货】Chrome插件(扩展)开发全攻略</a>这篇文章中看到，文中提到content-script只能操作DOM，但DOM却不能调用它，也就是说DOM没办法直接使用插件内部的js文件，只有通过向页面注入代码后才能调用，注入代码如下所示：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">// 向页面注入JS</span><br><span class="line">function injectCustomJs(jsPath)</span><br><span class="line">&#123;</span><br><span class="line">	jsPath = jsPath || &apos;js/inject.js&apos;;</span><br><span class="line">	var temp = document.createElement(&apos;script&apos;);</span><br><span class="line">	temp.setAttribute(&apos;type&apos;, &apos;text/javascript&apos;);</span><br><span class="line">	// 获得的地址类似：chrome-extension://ihcokhadfjfchaeagdoclpnjdiokfakg/js/inject.js</span><br><span class="line">	temp.src = chrome.extension.getURL(jsPath);</span><br><span class="line">	temp.onload = function()</span><br><span class="line">	&#123;</span><br><span class="line">		// 放在页面不好看，执行完后移除掉</span><br><span class="line">		this.parentNode.removeChild(this);</span><br><span class="line">	&#125;;</span><br><span class="line">	document.head.appendChild(temp);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>此外，还需要在配置文件中添加如下配置，不然会报 Resources must be listed in the web_accessible_resources manifest key in order to be loaded by pages outside the extension.</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">// 普通页面能够直接访问的插件资源列表，如果不设置是无法直接访问的</span><br><span class="line">&quot;web_accessible_resources&quot;: [&quot;js/inject.js&quot;],</span><br></pre></td></tr></table></figure>

<p>向页面注入localforage.js后发现，能够使用localforage了：</p>
<p><img src="/2020/07/20/etherscan-tags/image-20200717113439764.png" alt="image-20200717113439764"></p>
<p>localforage的使用可以参考这个网站：<a href="http://localforage.docschina.org/" target="_blank" rel="noopener">http://localforage.docschina.org/</a></p>
<p>localforage简单测试：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">window.onload=function()&#123;</span><br><span class="line">	localforage.setItem(&apos;key&apos;, &apos;value&apos;).then(</span><br><span class="line">		localforage.getItem(&apos;key&apos;, function(err, value) &#123;</span><br><span class="line">    // 当离线仓库中的值被载入时，此处代码运行</span><br><span class="line">    		console.log(value);</span><br><span class="line">		&#125;)</span><br><span class="line">	)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>导入插件后，刷新网页可以发现，成功插入了键值对key：value。</p>
<p><img src="/2020/07/20/etherscan-tags/image-20200717114624467.png" alt="image-20200717114624467"></p>
<p><img src="/2020/07/20/etherscan-tags/image-20200717114611209.png" alt="image-20200717114611209"></p>
<hr>
<p>此外，如果想要打包扩展程序后生成crx文件后在其他浏览器中导入，如果没有在chrome商店中上传并通过审核，会遇到如下问题：</p>
<p><img src="/2020/07/20/etherscan-tags/image-20200717113817539.png" alt="image-20200717113817539"></p>
<p>解决方案有两个：</p>
<p>第一个当然是花费5刀注册为chrome插件开发者，然后上传自己的插件，不过这中方式耗时很长，短期可以选择另一种方式；</p>
<p>第二个是修改本地组策略，在<a href="https://cloud.tencent.com/developer/article/1506583" target="_blank" rel="noopener">已解决!该扩展程序未列在 Chrome 网上应用店中，并可能是在您不知情的情况下添加的</a>这篇文章中介绍很详细。</p>
<hr>
<h2 id="最后"><a href="#最后" class="headerlink" title="最后"></a>最后</h2><p>完结撒花<em>★,°</em>:.☆(￣▽￣)/$:<em>.°★</em> 。，虽然本次尝试制作的插件功能比较简单，但却对我来说有实际的价值，大佬们不喜勿喷。</p>
]]></content>
      <categories>
        <category>区块链</category>
      </categories>
      <tags>
        <tag>Etherscan</tag>
        <tag>Chrome插件</tag>
      </tags>
  </entry>
  <entry>
    <title>区块链学习资料</title>
    <url>/2019/11/20/encrypt/</url>
    <content><![CDATA[<div id="hexo-blog-encrypt" data-wpm="抱歉, 这个密码看着不太对, 请再试试." data-whm="抱歉, 这个文章不能被校验, 不过您还是能看看解密后的内容."><div class="hbe-input-container"><input type="password" id="hbePass" placeholder="您好, 这里需要密码." /><label>您好, 这里需要密码.</label><div class="bottom-line"></div></div><script id="hbeData" type="hbeData" data-hmacdigest="d794ef138a6190707d71350e5f37c6b9464e47da56ead23ddd4b46adf028883e">66b988e26e34afa58004159beaf681e016e0ab23a2f8b58cdfa05194027d0556261919d6a7e5f608a945ce2bd66dd1e7970b50c8e80319d3e8aeecd62baa7914ffde2b532cb5c48e2fa4216590e39b458cc6a7697c151ddf12316b03d645ab81f07642cbb15872a501e2d7e1867fe077229a6cb63ee90e26a12565fcae80ca11</script></div><script src="/lib/blog-encrypt.js"></script><link href="/css/blog-encrypt.css" rel="stylesheet" type="text/css">]]></content>
      <categories>
        <category>区块链</category>
      </categories>
      <tags>
        <tag>资源</tag>
      </tags>
  </entry>
  <entry>
    <title>信息收集——绕过CDN寻找真实IP</title>
    <url>/2019/11/19/bypass-cdn/</url>
    <content><![CDATA[<h1 id="信息收集——绕过CDN寻找真实IP"><a href="#信息收集——绕过CDN寻找真实IP" class="headerlink" title="信息收集——绕过CDN寻找真实IP"></a>信息收集——绕过CDN寻找真实IP</h1><p>​    最近工作使用了很多CDN查询的网站工具之类的，为了以防以后忘记了，小小的总 (ban) 结 (yun) 一下。</p>
<p>​    以下是参考到的文章，感谢大佬们。</p>
<p>​    参考文章：</p>
<p> <a href="https://www.cnblogs.com/qiudabai/p/9763739.html" target="_blank" rel="noopener">https://www.cnblogs.com/qiudabai/p/9763739.html</a> </p>
<p> <a href="http://blog.leanote.com/post/snowming/CDN" target="_blank" rel="noopener">http://blog.leanote.com/post/snowming/CDN</a> </p>
<p> <a href="https://www.lsablog.com/networksec/penetration/some-ways-to-check-cdn-and-find-real-ip/" target="_blank" rel="noopener">https://www.lsablog.com/networksec/penetration/some-ways-to-check-cdn-and-find-real-ip/</a> </p>
<p> <a href="https://www.lstazl.com/cdn检测与绕过/" target="_blank" rel="noopener">https://www.lstazl.com/cdn%E6%A3%80%E6%B5%8B%E4%B8%8E%E7%BB%95%E8%BF%87/</a> </p>
<p>​    首先我们要了解什么是CDN：</p>
<blockquote>
<p>CDN 即 <code>content delivery network</code>，内容交付网络，通过在网络各处放置节点服务器所构成的在现有的互联网基础之上的一层智能虚拟网络，CDN系统能够实时地根据网络流量和各节点的连接、负载状况以及到用户的距离和响应时间等综合信息将用户的请求重新导向离用户最近的服务节点上。</p>
<p>开了CDN 之后，会智能匹配当地最近的节点来的，所以请求的实际 IP 不同。</p>
</blockquote>
<p>​    对用户来说CDN的存在能够使你访问网站的响应速度更快，用户体验更好。</p>
<p>​    对网站所有者来说，CDN的存在减轻了服务器的压力，同时也将真实服务器IP隐藏了起来，降低被黑客入侵的风险。</p>
<h2 id="验证是否存在CDN"><a href="#验证是否存在CDN" class="headerlink" title="验证是否存在CDN"></a>验证是否存在CDN</h2><h3 id="nslookup"><a href="#nslookup" class="headerlink" title="nslookup"></a>nslookup</h3><p>​    使用nslookup查询，如果查询结果是多个IP，则很大可能使用了CDN，如果返回一个IP也不一定是真实IP。</p>
<p>​    下面这种就是使用了CDN的：</p>
<p><img src="/2019/11/19/bypass-cdn/img1.png" alt></p>
<p>​    下面这种是没有使用CDN的：</p>
<p><img src="/2019/11/19/bypass-cdn/img2.png" alt></p>
<h3 id="多地ping"><a href="#多地ping" class="headerlink" title="多地ping"></a>多地ping</h3><p>​    使用各种多地 ping 的服务，查看返回的IP 地址是否唯一，如果返回的IP不是唯一的，那么很有可能使用了CDN。 </p>
<p>多地 Ping 网站有：<br><a href="http://ping.chinaz.com/" target="_blank" rel="noopener">http://ping.chinaz.com/</a><br><a href="http://ping.aizhan.com/" target="_blank" rel="noopener">http://ping.aizhan.com/</a><br><a href="https://www.17ce.com/" target="_blank" rel="noopener">https://www.17ce.com/</a><br><a href="https://wepcc.com/" target="_blank" rel="noopener">https://wepcc.com/</a></p>
<p><img src="/2019/11/19/bypass-cdn/img3.png" alt></p>
<p><img src="/2019/11/19/bypass-cdn/img4.png" alt></p>
<p><img src="/2019/11/19/bypass-cdn/img5.png" alt></p>
<p><img src="/2019/11/19/bypass-cdn/img6.png" alt></p>
<h3 id="响应头"><a href="#响应头" class="headerlink" title="响应头"></a>响应头</h3><p> <a href="http://www.12306.cn的响应头" target="_blank" rel="noopener">www.12306.cn的响应头</a></p>
<blockquote>
<p>Accept-Ranges: bytes<br>null: HTTP/1.1 200 OK<br>X-Cache: HIT from cache.51cdn.com<br>X-Via: 1.1 zib232:4 (Cdn Cache Server V2.0), 1.1 xz115:6 (Cdn Cache Server V2.0)<br>Connection: keep-alive<br>Last-Modified: Fri, 24 Oct 2014 09:24:58 GMT<br>Content-Length: 1480<br>Age: 22852<br>Date: Sat, 14 Oct 2017 04:22:44 GMT<br>X-Powered-By: Servlet/2.5 JSP/2.1<br>Content-Type: text/html</p>
</blockquote>
<p>从响应头字段可以看出cdn相关信息。 </p>
<h3 id="在线分析网站"><a href="#在线分析网站" class="headerlink" title="在线分析网站"></a>在线分析网站</h3><p><a href="https://builtwith.com/" target="_blank" rel="noopener">https://builtwith.com</a><br><a href="https://www.cdnplanet.com/tools/cdnfinder/" target="_blank" rel="noopener">https://www.cdnplanet.com/tools/cdnfinder/</a> </p>
<p><img src="/2019/11/19/bypass-cdn/img7.png" alt></p>
<p><img src="/2019/11/19/bypass-cdn/img8.png" alt></p>
<h3 id="dig"><a href="#dig" class="headerlink" title="dig"></a>dig</h3><p>​    通过dig命令查看DNS解析记录， 一般有的 CNAME 的大多数是 CDN。 </p>
<p><img src="/2019/11/19/bypass-cdn/img9.png" alt></p>
<h3 id="CDN厂商ASN号和CDN段列表"><a href="#CDN厂商ASN号和CDN段列表" class="headerlink" title="CDN厂商ASN号和CDN段列表"></a>CDN厂商ASN号和CDN段列表</h3><p>​    在这篇<a href="http://blog.leanote.com/post/snowming/CDN" target="_blank" rel="noopener">文章</a>中 ，提到了一中域名批量CDN检测的方式，使用python脚本来进行扫描，脚本来源于 <a href="https://github.com/al0ne/Vxscan" target="_blank" rel="noopener">vxscan</a>(Author: al0ne) 。</p>
<blockquote>
<p>​    这个脚本的原理是利用 ASN。ASN 是自治系统号，相同组织的 ASN 是一样的，所以一个 CDN 厂商的 IP 段可能都在一个 ASN 里。</p>
<p>​    判断逻辑如下：</p>
<ol>
<li>解析域名，获取解析之后的 IP；</li>
<li>判断此 IP 是否命中国内外常见 CDN 段，如果命中，说明有 CDN；</li>
<li>对此 IP 查询其对应的 ASN 号（通过 <code>response = reader.asn(host)</code> 这一句代码）。如果获取的 ASN 号命中了上面的国内外常见 CDN 厂商的 ASN 号，说明有 CDN；</li>
<li>如果通过这两次判断都没有命中，那么极有可能说明是真实 IP。</li>
</ol>
</blockquote>
<h2 id="绕过-CDN-查找网站真实-IP"><a href="#绕过-CDN-查找网站真实-IP" class="headerlink" title="绕过 CDN 查找网站真实 IP"></a>绕过 CDN 查找网站真实 IP</h2><h3 id="nslookup-1"><a href="#nslookup-1" class="headerlink" title="nslookup"></a>nslookup</h3><p>​    使用国外冷门DNS进行域名解析，可能解析到真实IP。</p>
<h3 id="查询历史DNS记录"><a href="#查询历史DNS记录" class="headerlink" title="查询历史DNS记录"></a>查询历史DNS记录</h3><p>​    查看 IP 与 域名绑定的历史记录，可能会存在使用 CDN 前的记录，相关查询网站有：</p>
<p><a href="https://dnsdb.io/zh-cn/" target="_blank" rel="noopener">    DNS查询</a><br><a href="https://x.threatbook.cn/" target="_blank" rel="noopener">    微步在线</a><br><a href="http://toolbar.netcraft.com/site_report?url=" target="_blank" rel="noopener">    在线域名信息查询</a><br><a href="http://viewdns.info/" target="_blank" rel="noopener">    DNS、IP等查询</a><br><a href="https://tools.ipip.net/cdn.php" target="_blank" rel="noopener">    CDN查询IP</a></p>
<p>​    SecurityTrails</p>
<p>​    利用<a href="https://securitytrails.com/" target="_blank" rel="noopener">SecurityTrails</a>平台，攻击者就可以精准的找到真实原始IP。他们只需在搜索字段中输入网站域名，然后按Enter键即可，这时“历史数据”就可以在左侧的菜单中找到。</p>
<p><img src="/2019/11/19/bypass-cdn/img11.png" alt></p>
<p>​    除了过去的DNS记录，即使是当前的记录也可能泄漏原始服务器IP。例如，MX记录是一种常见的查找IP的方式。如果网站在与web相同的服务器和IP上托管自己的邮件服务器，那么原始服务器IP将在MX记录中。</p>
<h3 id="查询子域名"><a href="#查询子域名" class="headerlink" title="查询子域名"></a>查询子域名</h3><p>​    很多站长可能只会对主站或者流量大的子站点做了 CDN，很多在同一台服务器或者同一个C段内的其他子站点就没有做CDN，此时就可以通过查询子域名对应的 IP 来辅助查找网站的真实IP。</p>
<p>​    修改host绑定到目标域名，能访问则目标域名和其子域名在同服务器，若不在可尝试c段。 </p>
<p>​    常用的子域名查找的方法和工具：</p>
<ol>
<li><p>一个大佬博客的工具：<a href="https://phpinfo.me/domain/" target="_blank" rel="noopener">https://phpinfo.me/domain/</a> </p>
<p><img src="/2019/11/19/bypass-cdn/img13.png" alt></p>
</li>
<li><p>微步在线(<a href="https://x.threatbook.cn/" target="_blank" rel="noopener">https://x.threatbook.cn/</a>)</p>
</li>
</ol>
<p>​    输入要查找的域名(如baidu.com)，点击子域名选项就可以查找它的子域名了，但是免费用户每月只有5次免费查询机会。如图：</p>
<p><img src="/2019/11/19/bypass-cdn/img12.png" alt="img"></p>
<ol start="3">
<li>Dnsdb查询法。(<a href="https://dnsdb.io/zh-cn/" target="_blank" rel="noopener">https://dnsdb.io/zh-cn/</a>)</li>
</ol>
<p>​    只需输入baidu.com type:A就能收集百度的子域名和ip了。如图：<br><img src="/2019/11/19/bypass-cdn/img14.png" alt="img"></p>
<ol start="4">
<li><p>Google 搜索</p>
<p>Google site:baidu.com -www 就能查看除www外的子域名，如图：</p>
</li>
</ol>
<p><img src="/2019/11/19/bypass-cdn/img15.png" alt="img"></p>
<ol start="5">
<li><p>各种子域名扫描器</p>
<p><a href="https://github.com/euphrat1ca/LayerDomainFinder" target="_blank" rel="noopener">子域名挖掘机</a></p>
<p>子域名挖掘机仅需输入域名即可基于字典挖掘它的子域名，如图：</p>
</li>
</ol>
<p><img src="/2019/11/19/bypass-cdn/img16.png" alt="img"></p>
<p>​    <a href="https://github.com/lijiejie/subDomainsBrute" target="_blank" rel="noopener">subdomainbrute</a></p>
<p>​    Subdomainbrute以windows为例，打开cmd进入它所在的目录输入    </p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Python subdomainbrute.py baidu.com --full</span><br></pre></td></tr></table></figure>

<p>​    即可收集百度的子域名，如图：</p>
<p><img src="/2019/11/19/bypass-cdn/img17.png" alt="img"></p>
<h3 id="网络空间引擎搜索法"><a href="#网络空间引擎搜索法" class="headerlink" title="网络空间引擎搜索法"></a>网络空间引擎搜索法</h3><ol>
<li><a href="https://www.zoomeye.org/" target="_blank" rel="noopener">钟馗之眼(Zoomeye)</a></li>
</ol>
<p><img src="/2019/11/19/bypass-cdn/img18.png" alt></p>
<p>​    zoomeye 用户手册： <a href="https://www.zoomeye.org/doc?channel=user" target="_blank" rel="noopener">https://www.zoomeye.org/doc?channel=user</a> </p>
<ol start="2">
<li><a href="https://fofa.so/" target="_blank" rel="noopener">Fofa</a></li>
</ol>
<p><img src="/2019/11/19/bypass-cdn/img19.png" alt></p>
<p>​    查询语法在搜索页面即可看到。</p>
<ol start="3">
<li><a href="https://www.shodan.io/" target="_blank" rel="noopener">Shodan</a></li>
</ol>
<p>​    搜索语法： <a href="https://help.shodan.io/the-basics/search-query-fundamentals" target="_blank" rel="noopener">https://help.shodan.io/the-basics/search-query-fundamentals</a> </p>
<p>​    通过这些网络空间搜索引擎， 网站的title关键字或者网站的body特征就可以找出收录的有这些关键字的ip域名，很多时候能获取网站的真实ip </p>
<h3 id="利用SSL证书寻找真实原始IP"><a href="#利用SSL证书寻找真实原始IP" class="headerlink" title="利用SSL证书寻找真实原始IP"></a>利用SSL证书寻找真实原始IP</h3><p>​    转自 <a href="https://www.cnblogs.com/qiudabai/p/9763739.html" target="_blank" rel="noopener">https://www.cnblogs.com/qiudabai/p/9763739.html</a> </p>
<blockquote>
<p>使用给定的域名</p>
<p>假如你在xyz123boot.com上托管了一个服务，原始服务器IP是136.23.63.44。 而CloudFlare则会为你提供DDoS保护，Web应用程序防火墙和其他一些安全服务，以保护你的服务免受攻击。为此，你的Web服务器就必须支持SSL并具有证书，此时CloudFlare与你的服务器之间的通信，就像你和CloudFlare之间的通信一样，会被加密（即没有灵活的SSL存在）。这看起来很安全，但问题是，当你在端443（<a href="https://136.23.63.44:443）上直接连接到IP时，SSL证书就会被暴露。" target="_blank" rel="noopener">https://136.23.63.44:443）上直接连接到IP时，SSL证书就会被暴露。</a></p>
<p>此时，如果攻击者扫描0.0.0.0/0，即整个互联网，他们就可以在端口443上获取在xyz123boot.com上的有效证书，进而获取提供给你的Web服务器IP。</p>
<p>目前Censys工具就能实现对整个互联网的扫描，Censys是一款用以搜索联网设备信息的新型搜索引擎，安全专家可以使用它来评估他们实现方案的安全性，而黑客则可以使用它作为前期侦查攻击目标、收集目标信息的强大利器。Censys搜索引擎能够扫描整个互联网，Censys每天都会扫描IPv4地址空间，以搜索所有联网设备并收集相关的信息，并返回一份有关资源（如设备、网站和证书）配置和部署信息的总体报告。</p>
<p>而攻击者唯一需要做的就是把上面用文字描述的搜索词翻译成实际的搜索查询参数。</p>
<p>xyz123boot.com证书的搜索查询参数为：parsed.names：xyz123boot.com</p>
<p>只显示有效证书的查询参数为：tags.raw：trusted</p>
<p>攻击者可以在Censys上实现多个参数的组合，这可以通过使用简单的布尔逻辑来完成。</p>
<p>组合后的搜索参数为：parsed.names: xyz123boot.com and tags.raw: trusted</p>
<p><img src="/2019/11/19/bypass-cdn/img20.png" alt="img"></p>
<p>Censys将向你显示符合上述搜索条件的所有标准证书，以上这些证书是在扫描中找到的。</p>
<p>要逐个查看这些搜索结果，攻击者可以通过单击右侧的“Explore”，打开包含多个工具的下拉菜单。What’s using this certificate? &gt; IPv4 Hosts</p>
<p><img src="/2019/11/19/bypass-cdn/img21.png" alt="img"></p>
<p>此时，攻击者将看到一个使用特定证书的IPv4主机列表，而真实原始 IP就藏在其中。</p>
<p><img src="/2019/11/19/bypass-cdn/img22.png" alt="img"></p>
<p>你可以通过导航到端口443上的IP来验证，看它是否重定向到xyz123boot.com？或它是否直接在IP上显示网站？</p>
<p>使用给定的SSL证书</p>
<p>如果你是执法部门的人员，想要找出一个隐藏在cheesecp5vaogohv.onion下的儿童色情网站。做好的办法，就是找到其原始IP，这样你就可以追踪到其托管的服务器，甚至查到背后的运营商以及金融线索。</p>
<p>隐藏服务具有SSL证书，要查找它使用的IPv4主机，只需将”SHA1 fingerprint”（签名证书的sha1值）粘贴到Censys IPv4主机搜索中，即可找到证书，使用此方法可以轻松找到配置错误的Web服务器。</p>
</blockquote>
<h3 id><a href="#" class="headerlink" title></a></h3><h3 id="HTTP标头寻找真实原始IP"><a href="#HTTP标头寻找真实原始IP" class="headerlink" title="HTTP标头寻找真实原始IP"></a>HTTP标头寻找真实原始IP</h3><blockquote>
<p>借助SecurityTrails这样的平台，任何人都可以在茫茫的大数据搜索到自己的目标，甚至可以通过比较HTTP标头来查找到原始服务器。</p>
<p>特别是当用户拥有一个非常特别的服务器名称与软件名称时，攻击者找到你就变得更容易。</p>
<p>如果要搜索的数据相当多，如上所述，攻击者可以在Censys上组合搜索参数。假设你正在与1500个Web服务器共享你的服务器HTTP标头，这些服务器都发送的是相同的标头参数和值的组合。而且你还使用新的PHP框架发送唯一的HTTP标头（例如：X-Generated-Via：XYZ框架），目前约有400名网站管理员使用了该框架。而最终由三个服务器组成的交集，只需手动操作就可以找到了IP，整个过程只需要几秒钟。</p>
<p>例如，Censys上用于匹配服务器标头的搜索参数是80.http.get.headers.server :，查找由CloudFlare提供服务的网站的参数如下：</p>
<p>80.http.get.headers.server:cloudflare</p>
<h3 id="-1"><a href="#-1" class="headerlink" title></a><img src="/2019/11/19/bypass-cdn/img25.png" alt="img"></h3></blockquote>
<h3 id="利用网站返回的内容寻找真实原始IP"><a href="#利用网站返回的内容寻找真实原始IP" class="headerlink" title="利用网站返回的内容寻找真实原始IP"></a>利用网站返回的内容寻找真实原始IP</h3><blockquote>
<p>如果原始服务器IP也返回了网站的内容，那么可以在网上搜索大量的相关数据。</p>
<p>浏览网站源代码，寻找独特的代码片段。在JavaScript中使用具有访问或标识符参数的第三方服务（例如Google Analytics，reCAPTCHA）是攻击者经常使用的方法。</p>
<p>以下是从HackTheBox网站获取的Google Analytics跟踪代码示例：</p>
<p>ga（’create’，’UA-93577176-1’，’auto’）;<br>可以使用80.http.get.body：参数通过body/source过滤Censys数据，不幸的是，正常的搜索字段有局限性，但你可以在Censys请求研究访问权限，该权限允许你通过Google BigQuery进行更强大的查询。</p>
<p>Shodan是一种类似于Censys的服务，也提供了http.html搜索参数。</p>
<p>搜索示例：<a href="https://www.shodan.io/search?query=http.html%3AUA-32023260-1" target="_blank" rel="noopener">https://www.shodan.io/search?query=http.html%3AUA-32023260-1</a></p>
<p><img src="/2019/11/19/bypass-cdn/img26.png" alt="img"></p>
</blockquote>
<h3 id="网站漏洞查找"><a href="#网站漏洞查找" class="headerlink" title="网站漏洞查找"></a>网站漏洞查找</h3><ol>
<li>目标敏感文件泄露，例如：phpinfo之类的探针、GitHub信息泄露等。</li>
<li>XSS盲打，命令执行反弹shell，SSRF等。</li>
<li>无论是用社工还是其他手段，拿到了目标网站管理员在CDN的账号，从而在从CDN的配置中找到网站的真实IP。</li>
</ol>
<h3 id="-2"><a href="#-2" class="headerlink" title></a></h3><h3 id="网站邮件订阅查找"><a href="#网站邮件订阅查找" class="headerlink" title="网站邮件订阅查找"></a>网站邮件订阅查找</h3><p>​    RSS邮件订阅，很多网站都自带 sendmail，会发邮件给我们，此时查看邮件源码里面就会包含服务器的真实 IP 了。</p>
<p>​    也可让服务器发送一些非HTML的数据，比如让服务器发送邮件给你，查看邮件原文即可获得SMTP服务器的真实IP。</p>
<p>​    注册邮件<br>​    密码重置邮件<br>​    广告推送邮件</p>
<p>​    如下图，可以通过显示邮件原文，在原文中可能会有目标站点的IP。<img src="/2019/11/19/bypass-cdn/img23.png" alt></p>
<p><img src="/2019/11/19/bypass-cdn/img24.png" alt></p>
<h3 id="用-Zmap-扫全网"><a href="#用-Zmap-扫全网" class="headerlink" title="用 Zmap 扫全网"></a>用 Zmap 扫全网</h3><blockquote>
<p>​    需要找 xiaix.me 网站的真实 IP，我们首先从 apnic 获取 IP 段，然后使用 Zmap 的 banner-grab 扫描出来 80 端口开放的主机进行 banner 抓取，最后在 http-req 中的 Host 写 xiaix.me。</p>
</blockquote>
<h3 id="-3"><a href="#-3" class="headerlink" title></a></h3><h3 id="F5-LTM解码法"><a href="#F5-LTM解码法" class="headerlink" title="F5 LTM解码法"></a>F5 LTM解码法</h3><blockquote>
<p>​    当服务器使用F5 LTM做负载均衡时，通过对set-cookie关键字的解码真实ip也可被获取，例如：Set-Cookie: BIGipServerpool_8.29_8030=487098378.24095.0000，先把第一小节的十进制数即487098378取出来，然后将其转为十六进制数1d08880a，接着从后至前，以此取四位数出来，也就是0a.88.08.1d，最后依次把他们转为十进制数10.136.8.29，也就是最后的真实ip。</p>
</blockquote>
<h3 id="DOS"><a href="#DOS" class="headerlink" title="DOS"></a>DOS</h3><p>​     打光cdn流量，回溯真实ip。 这种不能轻易尝试，造成严重后果就不好了。</p>
<h3 id="针对CloudFlare"><a href="#针对CloudFlare" class="headerlink" title="针对CloudFlare"></a>针对CloudFlare</h3><p>​    如果目标站点使用的是cloudflare的CDN，可以去<a href="http://www.crimeflare.org:82/cfs.html#box" target="_blank" rel="noopener">crimeflare</a> 碰碰运气，说不定就会又意外的发现哦。</p>
<h2 id="验证真实IP"><a href="#验证真实IP" class="headerlink" title="验证真实IP"></a>验证真实IP</h2><p>​    找到真实 IP 后 先访问 IP 看看和原站是否一样。 如果不能直接访问，可能做了IP访问限制，可以通过修改hosts再访问网站，测试是否成功。 </p>
]]></content>
      <categories>
        <category>web渗透</category>
      </categories>
      <tags>
        <tag>信息收集</tag>
        <tag>安全</tag>
      </tags>
  </entry>
</search>
